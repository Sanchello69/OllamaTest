version: '3.8'

services:
  # Ollama сервис для генерации эмбеддингов
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Инициализация модели (запускается один раз)
  ollama-init:
    image: ollama/ollama:latest
    container_name: ollama-init
    depends_on:
      ollama:
        condition: service_healthy
    volumes:
      - ollama_data:/root/.ollama
    entrypoint: /bin/sh
    command:
      - -c
      - |
        echo "Pulling nomic-embed-text model..."
        ollama pull nomic-embed-text
        echo "Model ready!"
    restart: "no"

  # Приложение (раскомментируйте после сборки образа)
  # app:
  #   build: .
  #   container_name: ollama-embeddings-app
  #   depends_on:
  #     ollama:
  #       condition: service_healthy
  #   volumes:
  #     - ./:/app/data
  #   environment:
  #     - OLLAMA_HOST=http://ollama:11434
  #   network_mode: "service:ollama"
  #   # Для запуска с аргументами используйте docker-compose run
  #   # docker-compose run --rm app index /app/data/example.rtf

volumes:
  ollama_data:
    driver: local
